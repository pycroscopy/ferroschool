{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6bcce3c2",
   "metadata": {},
   "source": [
    "# SciFiReaders and sidpy\n",
    "\n",
    "By R. Vasudevan\n",
    "\n",
    "SciFiReaders is a package that can read in a variety of microscopy datasets. The data is then read into a sidpy Dataset object, which enables easy plotting and analysis through other pycroscopy tools.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67da2ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U pyNSID sidpy SciFiReaders nanonispy gwyfile pycroscopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2c4cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e1aa1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import SciFiReaders as sr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc8c303",
   "metadata": {},
   "source": [
    "## Load a gwyddion file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16da7cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r'data/fig2a.gwy'\n",
    "gwy_reader = sr.GwyddionReader(file_path)\n",
    "gwy_data = gwy_reader.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3997766",
   "metadata": {},
   "outputs": [],
   "source": [
    "gwy_data[2].plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5424d2a",
   "metadata": {},
   "source": [
    "## Load a DM3 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2e6d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Try another one\n",
    "file_path = r'data/bto_atomic.dm3'\n",
    "dm3_reader = sr.DM3Reader(file_path)\n",
    "dm3_data = dm3_reader.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d4f565",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm3_data.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7580b9f2",
   "metadata": {},
   "source": [
    "## Load a spectroscopy dataset\n",
    "\n",
    "In this case, this will be tunneling spectroscopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748ad1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "file_path = r'data/STS_lockin.3ds'\n",
    "ds_reader = sr.Nanonis3dsReader(file_path)\n",
    "ds_data = ds_reader.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8577065",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = ds_data[0].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a4f0c1",
   "metadata": {},
   "source": [
    "## Exercise: Load your own dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916ad3d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4d238383",
   "metadata": {},
   "source": [
    "# Sidpy\n",
    "\n",
    "By Gerd Duscher and Suhas Somnath\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e3a8d0",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Ensure python 3 compatibility:\n",
    "from __future__ import division, print_function, absolute_import, unicode_literals\n",
    "\n",
    "%pylab notebook\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, '../../')\n",
    "import sidpy\n",
    "print('sidpy version: ', sidpy.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4dcba89",
   "metadata": {},
   "source": [
    "## Creating a ``sipy.Dataset`` object\n",
    "We can create a simple sidpy Dataset from any array like object\n",
    "Here we just use a numpy array filled with zeros\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e309e6",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "data_set = sidpy.Dataset.from_array(np.random.random([4, 5, 10]), name='random')\n",
    "\n",
    "print(data_set)\n",
    "data_set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57950993",
   "metadata": {},
   "source": [
    "Note that ``data_set`` is a dask array....\n",
    "We will be improving upon the information that will be displayed when printing ``sidpy.Dataset`` objects\n",
    "\n",
    "Accessing data within a ``Dataset``:\n",
    "Indexing of the dataset works like in numpy\n",
    "Note, that we first index and then we make a numpy array for printing reasons\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e87ae7a",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "print(np.array(data_set[:,0,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a826ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can easily add metadata\n",
    "blobs = np.random.normal(size=(10,2))\n",
    "\n",
    "data_dictionary = {\"main_dataset\": data_set, \n",
    "                   'new_dataset': data_set, \n",
    "                   'metadata': {'atoms': blobs}, \n",
    "                   }\n",
    "\n",
    "data_dictionary['new_dataset'].metadata = {\"origin_dataset\": 'main_dataset'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1cb752",
   "metadata": {},
   "source": [
    "## Metadata\n",
    "``sidpy`` automatically assigns generic top-level metadata regarding the\n",
    "``Dataset``. Users are encouraged to capture the context regarding the dataset.\n",
    "The attributes included in the sidpy dataset are \n",
    "Required Attributes:\n",
    "\n",
    "- ``quantity``: string: Physical quantity that is contained in this dataset\n",
    "\n",
    "- ``units``: string: Units for this physical quantity\n",
    "\n",
    "- ``data_type``: string : What kind of data this is. Example - image, image stack, video, hyperspectral image, etc.\n",
    "\n",
    "- ``modality``: string : Experimental / simulation modality - scientific meaning of data. Example - photograph, TEM micrograph, SPM Force-Distance spectroscopy.\n",
    "\n",
    "- ``source``: string : Source for dataset like the kind of instrument. One could go very deep here into either the algorithmic details if this is a result from analysis or the exact configurations for the instrument that generated this dataset.\n",
    "\n",
    "Those attributes are set to ``generic`` originally but one would want to set them\n",
    "for the specific dataset. The attributes ``data_type``, ``quantity`` and ``units``  will be important for plotting the data.\n",
    "\n",
    "Here's how one could do that, but with the wrong key word:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f3ea78",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "data_set.data_type = 'spectrum_image'  # not supported"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161f472f",
   "metadata": {},
   "source": [
    "Here's how one could do that sucessfully:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75e61ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set.data_type = 'spectral_image'  # supported\n",
    "\n",
    "data_set.units = 'nA'\n",
    "data_set.quantity = 'Current'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecae5515",
   "metadata": {},
   "source": [
    "### Scientific metadata\n",
    "These ``Dataset`` objects can also capture rich scientific metadata such as\n",
    "acquisition parameters, etc. as well:\n",
    "We would want to add those parameters as attributes.\n",
    "These attributes could be lists, numpy arrays or simple dictionaries.\n",
    "It is encouraged to add any parameters of data analysis to the datasets,\n",
    "to keep track of input parameters. Here I made some up as an illustration:\n",
    "\n",
    " These ``Dataset`` objects can also capture rich scientific metadata such as acquisition parameters, etc. as well:\n",
    "\n",
    "We would want to add those parameters as attributes. These attributes could be lists, numpy arrays or simple dictionaries. It is encouraged to add any parameters of data analysis to the datasets, to keep track of input parameters.\n",
    "\n",
    "It is recommended to add any parameters to the (nested) metadata dictionary.\n",
    "These metadata can then be viewed in dataset.view_metadata and dataset.view_original_metadata. It is encouraged to add any parameters of data analysis to the datasets, to keep track of input parameters.\n",
    "\n",
    "There is a size limit of 64kB for the storage of dictionaries in h5py. Therefore, large data such as reference data should be added directly as attributes. All attributes that you add to a dataset will be stored within the pyNSID file. \n",
    " \n",
    "Please note, that the dictionary ``original_metadata`` should not be changed so that information provided by the acquisition device stays pristine, but relevant inforamtion should be copied over to the ``metadata`` attribute/dictionary.\n",
    "\n",
    "Here I made up some metadata as an illustration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfa24ff",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "data_set.calibration = np.arange(5)\n",
    "data_set.metadata = {'nothing': ' ', 'value': 6.8, 'instrument': {'microscope': 'Nion', 'acceleration_voltage':60000}}\n",
    "data_set.metadata['acquired'] = 'nowhere'\n",
    "\n",
    "print(data_set.calibration)\n",
    "sidpy.dict_utils.print_nested_dict(data_set.metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840b150b",
   "metadata": {},
   "source": [
    "Another set of metadata in these Datasets is the Dimension ones:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46235ff",
   "metadata": {},
   "source": [
    "## Dimensions\n",
    "The ``Dataset`` is automatically populated with generic information about\n",
    "each dimension of the ``Dataset``. It is a good idea to capture context\n",
    "regarding each of these dimensions using ``sidpy.Dimension``.\n",
    "As a minimum we need a name and values (of the same length as the dimensions of the data).\n",
    "One can provide as much or as little information about each dimension.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e1cbe7",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "data_set.set_dimension(0, sidpy.Dimension(np.arange(data_set.shape[0]), \n",
    "                                          name='x', units='um', quantity='Length',\n",
    "                                          dimension_type='spatial'))\n",
    "data_set.set_dimension(1, sidpy.Dimension(np.linspace(-2, 2, num=data_set.shape[1], endpoint=True),\n",
    "                                          'y', units='um', quantity='Length',\n",
    "                                          dimension_type='spatial'))\n",
    "data_set.set_dimension(2, sidpy.Dimension(np.sin(np.linspace(0, 2 * np.pi, num=data_set.shape[2])),\n",
    "                                          'bias' ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e74cf53",
   "metadata": {},
   "source": [
    "One could also manually add information regarding specific components of\n",
    "dimensions associated with Datasets via:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc9902f",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "data_set.bias.dimension_type = 'spectral'\n",
    "data_set.bias.units = 'V'\n",
    "data_set.bias.quantity = 'Bias'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f440bb",
   "metadata": {},
   "source": [
    "Let's take a look at what the dataset looks like with the additional information\n",
    "regarding the dimensions. \n",
    "\n",
    "We can access a dimension by its name or by the dimension number.\n",
    "\n",
    "Also the print function now provides a little more information about our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b79954",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "print(data_set.bias)\n",
    "print(data_set.dim_1)\n",
    "print(data_set)\n",
    "data_set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df330bb",
   "metadata": {},
   "source": [
    "## Plotting\n",
    "The ``Dataset`` object also comes with the ability to visualize its contents\n",
    "using the ``plot()`` function. Here we only show a simple application, but a more\n",
    "detailed description can be found in the plotting section.\n",
    "Here we plot a spectral image you can click in the image part of the plot on the\n",
    "left and the spectrum on the right will update.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059b2bd5",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = data_set.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356641cf",
   "metadata": {},
   "source": [
    "The plotting depends on the data_type of the dataset and the dimension_types\n",
    "of it's dimension datasets. Above, we set the first two dimension_type types to\n",
    "``spatial`` and the third one to ``spectral``.\n",
    "\n",
    "The data_type was ``spectral_image``.\n",
    "So the spatial dimensions are recognized as relevant for an image and the third dimension is recognized as a spectrum, conducive to plotting as shown above.\n",
    "If we change the data_type to image, the default plotting behavoir is to plot the first slice in the dataset (i.e. data_set[:,:,0]).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f395e7e7",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_set.data_type = 'image'\n",
    "fig = data_set.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d7d320",
   "metadata": {},
   "source": [
    "## Saving\n",
    "\n",
    "These ``Dataset`` objects will be deleted from memory once the python script\n",
    "completes or when a notebook is closed. The information collected in a\n",
    "``Dataset`` can reliably be stored to files using functions in sister\n",
    "packages - ``pyUSID`` and ``pyNSID`` that write the dataset according to the\n",
    "**Universal Spectroscopy and Imaging Data (USID)** or **N-dimensional\n",
    "Spectrocsopy and Imaging Data (NSID)** formats.\n",
    "Here are links to how one could save such Datasets for each package:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad33381",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyNSID as nsid\n",
    "\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9502882e",
   "metadata": {},
   "outputs": [],
   "source": [
    "h5_f = h5py.File('my_file.h5', 'a')\n",
    "h5_grp = h5_f.create_group('My_Data')\n",
    "nsid.io.write_nsid_dataset(data_set, h5_grp, main_data_name='test dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4946cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sidpy.hdf_utils.print_tree(h5_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a80163",
   "metadata": {},
   "outputs": [],
   "source": [
    "h5_f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f211cac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
